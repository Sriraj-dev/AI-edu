{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first look at the main algorithms in unsupervised learning\n",
    "\n",
    "- Clustering\n",
    "- Anamoly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering basically means, it can observe the data and find patterns in it such that it groups similar type of data together.\n",
    "\n",
    "**Applications include**\n",
    "- Grouping similar news together\n",
    "- Understanding market segments for a business\n",
    "- Grouping people that exhibit similar traits etc...\n",
    "\n",
    "One of the algorithm which uses the concept of clustering is **K-means Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster simply signifies a group of datapoints, In k-means clustering we try to find out the centres of clusters. Let us suppose if we have 2 clusters in our data set , the process goes like this:\n",
    "\n",
    "- Assume 2 random points as cluster centroids.\n",
    "- Loop:\n",
    "    - Assign every datapoint to its closest centroid\n",
    "    - Now move the centorids to the mean value of the datapoints assigned to that particular centroid\n",
    "    - repeat the process\n",
    "- You will eventually endup when centroids are no longer moving , These are the exact centroid points of the clusters in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can even apply k-means clustering on the data even when there are no clear clusters, but you actually wanna divide the data into different groups. Example: You might have the data of height and weight of people, in which you obv dont see any specific clusters, but if you want to divide them into - small,medium,large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we already have the algorithm which helps us to find the cluster centroids, cost function will help us to decide, when to stop out loop(may be sometimes centroids always keeps updating in every iteration). You can also decide to stop if the cost function is converging in a very slow rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function is defined as,\\\n",
    "J = 1/m * iterate ( (x_i - u_c_i) ** 2 ) \\\n",
    "This cost function is also referred as distortion function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_i = ith datapoint of the dataset\\\n",
    "c_i = index of the cluster centroid to which x_i is assigned\\\n",
    "u_c_i = centroid point @ c_i th index to which x_i is assigned.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe in every iteration, this cost function minimizes as x_i is always assigned to its closest centroid point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first step in this algorithm was to initialise the k-means with random cluster centroids. Lets look at how you can actually do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you visualise the algorithm , you may observe that the final result actually depends on the initial considerations of the cluster centroids (they might endup in different locations other than the one which is expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./LearningAlgorithms/image.png\" alt=\"Visualisation\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to actually run a loop over the k-means algorithm which we mentioned above.\\\n",
    "Instead of running k-means once, you run it 100-1000 times and then can decide which iteration gave you the least cost using cost calculation. Typical no.of iteration runs from 50-1000 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to chose number of cluster centroid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is actually no proper conculsion that a data has exactly k clusters, there may be 2,3,4 or 6 clusters , its upto you to divide the data into required no. of clusters. But we also do have a method to decide the no.of clusters, in case you want to. (not always preferred ofc).\\\n",
    "\n",
    "**Elbow method** \n",
    "\n",
    "<img src = \"./LearningAlgorithms/image-1.png\" alt = \"Elbow method\" width = \"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usually, you perform k-means on a specific purpose which actually helps you to decide the k.\n",
    "- for the same example of T-shirt manufacturing, with the given data(weight & height) it depends on you whether you would like to divide it into 3 clusters(S,M,L sizes) or 5 clusters (XS,S,M,L,XL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anamoly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is basically a technique to point out something which is unusual or events which deviate from majority of the data.\n",
    "\n",
    "<img src=\"./LearningAlgorithms/image-2.png\" alt=\"anamoly detection\" width = \"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications**\n",
    "- Used to detect fake accounts\n",
    "- Used in financial fraud detection\n",
    "- Used in monitoring websites from effective bots\n",
    "- Used in manufacturing services to check for a imperfect manufacturing\n",
    "- Used to monitor computers in data center. etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./LearningAlgorithms/image-4.png\" alt = \"gaussian graph\" width = \"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src = \"./LearningAlgorithms/image-5.png\" alt = \"Gaussian formula\" width = \"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian formula uses mean and variance to give a estimate of the probability of the occurance of a given x, which we can use in our anamoly detection to sense the probability of occurance of an event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a example with multiple features, we do calculate the gaussian probability of each feature and then you can calculate p(x) as the product of each features probability. \\\n",
    "We choose a value epsilon & if p(x) < epsilon , we detect it as anamoly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we chose epsilon value / evaluate the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./LearningAlgorithms/image-6.png\" alt = \"chosing epsilon\" width = \"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basically you first fit the training data(without labels) to our model.\n",
    "- Now, to evaluate the model , you can use precision/recall method.\n",
    "- Although this is unsupervised learning , we might want to use some labelled data in cross validation set, which will help us to modify the parameter epsilon or make some changes to the features to improve its performance.\n",
    "- Then , you can also have a test set(labelled) to report the performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, In the practical process of building a anamoly system might require some labelled data(atleast small number) to fine tune the parameters of the model.\\\n",
    "As we are ofcourse using labelled data to test/evaluate the model, why cant we use supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anamoly detection Vs Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, when we have small number of positive examples(anamolies) in a large number of negative examples(normal/nothing suspicious), anamoly detection works completely fine.\\\n",
    "Lets look at how each of these algorithms actually look at the data in different pov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anamoly Detection**\n",
    "- This algorithm basically learns from the normal examples & will be then able to predict the examples which are far from normal(suspicious).\n",
    "- It can even detect a new defect which may come in future.\n",
    "- Hence , it is used in fraud detection, manufacturing services for suspicious defects, monitor computers in data center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning**\n",
    "- This algorithm tries to learn patterns in the data, even when you fewer amount of data on positive examples, it might or might not be able to learn the patterns of anamolity. Even if it does, it may not be able to predict a new kind of anamoly in future.\n",
    "- This can be used when you feel like, same kind of anamolity is going to be repeated and no new kind of anamolity will arise\n",
    "- This can also be used when you have huge data on positive and negative examples.\n",
    "- This is used in spam detection(same type of spam emails are repeated), manufacturing purposes to detect similar kind of faults(screen crack fault), weather prediction, diesease classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to chose features for anamoly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised learning it turns out that it can figure out the relations even when you have some additional unused features because it has a labelY. In this case, it becomes more important to chose proper features in anamoly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the techniques you might use to chose features are\n",
    "\n",
    "1. **Non Gaussian Features** \n",
    "- Non gaussian features might not give you proper predicitions, these are the features with histogram tilted towards left or right.\n",
    "<img src = \"./LearningAlgorithms/image-7.png\" alt = \"Non gaussian Feature\" width = \"400\"/>\n",
    "\n",
    "- In such cases we convert the feature into some other feature which might gives us closer result to gaussian graph. Log(x) is one such kind you can try to make it gaussian as shown in figure.\n",
    "- Log(x) or ^2 or ^0.5 or ^0.25 etc can be used to make it gaussian.\n",
    "\n",
    "2. **Error Analysis** (Assuming you have the right epsilon)\n",
    "- In this technique, you will have to keenly observe the failed examples in CV set, you might be able to find some relation due to which your model is unable to predict that anamoly.\n",
    "- feature x1 & x2 might be in the normal range, but x1 is too high than x2 which may not expected in normal case, in such situation , you can create a new feature like x1/x2. or similar to that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

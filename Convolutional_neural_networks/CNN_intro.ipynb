{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural networks, if we wanna train with images of larger size say 1000x1000 pixels, it would take billions of parameters and is computationally expensive and so we have concept called convolutions which is the fundamental concept of convolutional neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](vertical_edge_detection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We make a convolution operation between image and a filter which then results in a image where vertical edges are detected!\n",
    "- A horizontal edge detector will have a filter which is transpose of the filter in vertical edge detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In edge detection we typically have 2 problems.\n",
    "    - Image is always shrinked when we convolve it with filter and in case of deep neural network, the image will be shrinked a lot when compared to the input image.\n",
    "    - If we observe the operation of the convolution, we are not utilising the info of the edges as much as the pixels in middle! So we are missing out info on the edges!\n",
    "\n",
    "- In order to fix both of these operations, we can pad the image before applying convolve operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](padding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Valid Convolution** : No padding!\n",
    "- **Same Convolution** : adding padding such that input dimension = output dimension.i.e. p = (f-1) / 2.\n",
    "- Basically, image with nxn is convolved with fxf filter, to get (n-f+1)x(n-f+1) output. When we added padding of (p), the input dimension becomes (n+2p)x(n+2p) and output image accordingly.\n",
    "- So, f is usually odd, because same convolution is possible in case of odd f but this is not a standard reason for odd f, but usually we use filters with odd f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strided Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](strided_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slight change in the way of operating convolution, is that if we have 2 strides, we are gonna move two steps instead of 1 step while performing the convolve operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](strided_form.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution over volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- May be our image has a 3 channels of RGB, This case our iamge wont be a 2D matrix, but will be a 3D matrix.\n",
    "- This time our filter will also have the same no.of cahnnels like the input image, and the operation is similar to the 2D matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](volume_conv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer of Convolution neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see in the above image, a layer can have multiple filters, where in each filter(3D matrix) will give us a 2D output which are stacked to produce a 3D matrix and will act as input for the next layer.\n",
    "- The amazing thing in these networks is that, no.of parameters in a layer = no.of filters(units) * filter size. & this doesnt depend on the size of the input image as in simple NN.\n",
    "- If a filter is 3x3x3 which is having 27 parameters + bias = 28 & if we have 10 units in a layer, we get 280 parameters which is independent of the size of the input image, which helps a lot in space optimisation.\n",
    "- So, if we think dimensions of output of layer l can be given by the formula in the above image and the no.of channels given by layer l will be = no.of units in that layer.\n",
    "- Think about this, no.of channels in filters of layer l = no. of channels of the input to layer l = no. of units in layer l-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](conv_layer_notation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Till now, we have been learning about convolutional layers.\n",
    "- In conv layer, we do have paramters to learn but in **maxPool** layers we dont have any paramters to learn.\n",
    "- Although we do have hyperparameters(f,strides,padding) but no paramters to learn.It simply takes the max value from the matrix formed by placing filter over input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](max_pool_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- & if there is a 3D matrix in the left side with nc channels, then the output is also gonna have nc channels & the computation of eaxh channel will be of same process.\n",
    "- Sometimes we can use average poolinmg, which takes the average of the values of that matrix, but mostly we use maxpooling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

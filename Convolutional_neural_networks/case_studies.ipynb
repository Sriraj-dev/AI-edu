{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This module is basically to give an intuition to how to use the tools of conv neural network and building effective conv network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LeNet - 5 \n",
    "\n",
    "![Alt text](lenet-5_structure.png)\n",
    "- AlexNet\n",
    "\n",
    "![Alt text](alexnet_structure.png)\n",
    "\n",
    "- VCG-16 (16 layers)\n",
    "\n",
    "![Alt text](vcg-16_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Networks / connections [ResNet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In residual networks, activation from layer l skips some of the layers and is injected into the deeper layer in the network, which is caled as residual block!\n",
    "- By having these residual blocks it is observed that it doesnt create any issue upon increasing #layers in the network, but in plain network the training performance decreases!!! as we increase #layers in the network.\n",
    "\n",
    "![Alt text](residual_block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 1x1 convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](1x1_convLayer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead of directly applying the 5x5 conv layer on 28x28x192 which is computationally expensive, because to generate each number in the output u need to carryout multiple operations of product.\n",
    "- We first compress the number of channels using 1x1 conv layer which helps us in reducing the computation req. and then apply a 5x5 conv layer.\n",
    "- It turns out that this compression of channels using 1x1 layer doesnt effect the performace in a negative way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](inception_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The parallel convolutional branches with different filter sizes enable the network to capture features at multiple scales in an efficient manner.\n",
    "-  By incorporating multiple parallel pathways, the Inception module facilitates the flow of information through the network, allowing for richer feature learning and better gradient flow during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](inception_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ResNets and Inception networks still require computational power, MobileNet are designed to work even on low computational power GPUs/CPUs like mobile phones.\n",
    "- In normal convolution, each filter is applied to the input to generate a 2D sheet & x filters will give us x channels in the output. But in depthwise convolution, filters are 2D sheets and each filter is applied to one of the channels in the input which results in the output with same no. of channels.\\\n",
    "For example, if input has 3 channels, we will have 3 x 2D filters and each filter is applied to each channel results in 3 channels of output!.\n",
    "- i.e. Depthwise convolutions are around 10 times computationally cheaper when compared to normal convolutions\n",
    "- Depthwise convolutions have 2 steps : \n",
    "    - channels x 2D filters as mentioned above which results output with same channels as input.\n",
    "    - output from the first step is passed through 1x1 conv layer to compress or extend the no.of channels as required which is called as pointwise convolution step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](mobilenetV2_block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](mobilenet_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is a process which helps us to determine the resolution, depth , width of a network which gives best results for a given computational constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical application methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can download the CNN architecture from github of others implementations & start training them.\n",
    "- Dont have big enough data? We can take the help of transfer learning, we can download the architecutre & the weights of the network & then reuse them in our training by just changing the weights of the ending layers and output layer.\n",
    "- The more data its the more better it is in CV tasks, we can acheive this by data augmentation which has the following types:\n",
    "    - Mirroring the images.\n",
    "    - Random cropping (crop the picture & feed it to the network)\n",
    "    - Rotation (not used mostly)\n",
    "    - Shearing (not used mostly)\n",
    "    - Local Warping (not used mostly)\n",
    "    \n",
    "    - Color shifting : RGB Image  + (+20,-20,+20) = New image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

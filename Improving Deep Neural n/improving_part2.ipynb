{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch Gradient Descent (mini-batch size = m)\n",
    "- Mini-batch gradient descent (mini-batch size = somewhere between 1 & m)\n",
    "- Stochastic gradient descent (mini-batch size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you chose mini-batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If there isa  small training set - use batch gradient descent (m <= 2000)\n",
    "- Typical mini-batch size - 64 ,128 , 256, 512."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](momentum_gradient.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we are averaging out the gradient across the previous mini batches, we end up having less osscilations.\n",
    "- As you can see in the figure, it lowers the oscillations vertically and speeds up the horizontal movement which results in faster convergence.\n",
    "- Note: when beta = 0.9, it means we are averaging over last 10 iterations of gradient! This is a concept of exponential weighted average.\n",
    "- i.e. alpha(learning rate) & beta (weighted average constant) both play a major role in convergence when we use gradient descen twiht momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop (Root mean square prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](RMSprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a combination of RMSprop & momentum concept. It is observed that it boosts the convergence process.\n",
    "- It computes separate adaptive learning rates for each parameter, allowing it to dynamically adjust the learning rates based on the magnitude of the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usually we need a higher alpha in the beginning but lower alpha in the ending, this can be acheived by learning rate decay.\n",
    "- There are different formulaes to acheive this, but the most usual formulae goes like this:\n",
    "alpha = (1 / (1 + decayRate * epoch)) * alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
